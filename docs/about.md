---
title: About us
layout: about
permalink: /about/
---

## Motion AI Team

Motion AI Team believes that the virtual character will become more realistic than the human beings.
Eventually, people could communicate with virtual entertainers in real life, and play with them in the virtual world. <br>
To prepare for that era, our team members focus on generating natural motions of virtual character.
The motions we are interested in creating are not only imitating how humans act, but also learning and expressing how humans feel.

Currently, we eager to find the solution among deep learning approaches using motion capture data. <br>
NCSOFT has a world-level motion capture studio and professional technicians. AI Center at NCSOFT has started in 2012, and has been applying various AI algorithms to commercial games. Based on these environments Motion AI Team at AI Center, NCOSFT is continuously researching novel motion algorithms and trying to apply the algorithms to our game characters.

## R&D Topics

<img width="600" src="/images/posts/2019-04-22-topics.png"> <br>
Motion AI Team has two research branches: Facial & Body Animations. <br>
The outputs are found in <a href="https://nc-moai.github.io/blog/#research"> Blog >> Research</a>. <br>
We hope you enjoy that link, and if you have any question, feel free to <a href="mailto:ncdrjang@ncsoft.com"> contact us</a>.


## Members

|       | Name       |  Field of Research                                            |
|-------|------------|---------------------------------------------------------------|
| <figure style="width:100px"><img src="{{ '/images/profiles/ncdrjang.jpg' | absolute_url }}"></figure> | Hanyoung Jang (Team Leader) | Game AI, Computer Graphics, General-purpose GPUs, Robotics |
| <figure style="width:100px"><img src="{{ '/images/profiles/requiem4546.png' | absolute_url }}"></figure> | Byungjun Kwon | Deep Learning, Character Animation, Performance Capture |
| <figure style="width:100px"><img src="{{ '/images/profiles/dtrca.png' | absolute_url }}"></figure> | Jungsu Park | Speech Recognition, Facial Animation, Deep Learning |
| <figure style="width:100px"><img src="{{ '/images/profiles/eunbi.png' | absolute_url }}"></figure> | Eunbi Seol | Facial Performance Capture, Facial Animation |
| <figure style="width:100px"><img src="{{ '/images/profiles/jaekyuoh.png' | absolute_url }}"></figure> | Jaekyu Oh | Facial Animation, Deep Learning |
| <figure style="width:100px"><img src="{{ '/images/profiles/june5.png' | absolute_url }}"></figure> | June Oh | Facial Animation, Machine Learning |
| <figure style="width:100px"><img src="{{ '/images/profiles/moonwonyu.png' | absolute_url }}"></figure> | Moonwon Yu | Inverse Kinematics, Style Transfer, Character Animation |
| <figure style="width:100px"><img src="{{ '/images/profiles/yoondm.png' | absolute_url }}"></figure> | Dumim Yoon | Facial Performance Capture, 3D Reconstruction |
| <figure style="width:100px"><img src="{{ '/images/profiles/whcjs13.png' | absolute_url }}"></figure> | Kyungho Lee | Character Animation, Deep Learning |
| <figure style="width:100px"><img src="{{ '/images/profiles/minwook.png' | absolute_url }}"></figure> | Minwook Chang | Motion Capture, Generative Adversarial Networks, Human-Computer Interaction |
| <figure style="width:100px"><img src="{{ '/images/profiles/swchung.png' | absolute_url }}"></figure> | Seongwoo Chung | Facial Performance Retargeting, Direct Manipulation, Computer Graphics |

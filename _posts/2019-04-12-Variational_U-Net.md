---
title: "SIGGRAPH Asia 2018: A Variational U-Net for Motion Retargeting"
date: 2019-04-12 11:11:00
categories:
  - News
author: eunbi
---

In this paper, we present a novel motion retargeting system by using the deep autoencoder combining the Deep Convolution Inverse Graphics Network (DC-IGN) ([Kulkarni et al. 2015]) and the U-Net ([Long et al. 2015]) to produce high-quality human motion. The retargeted motion is fully-automatically and naturally generated from the given input motion and bone length ratios. To validate the proposed motion retargeting system, we conduct several experiments and achieve more accuracy and less computational burden when compared with the conventional motion retargeting approach and other neural network architectures.

<iframe width="560" height="315" src="https://www.youtube.com/embed/Kv2ayFELxHg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>

### Authors

Hanyoung Jang, Byungjun Kwon, Moonwon Yu(NCSOFT), Seong Uk Kim, Jongmin Kim(Kangwon National University)

### Proceeding

SA '18 SIGGRAPH Asia 2018 Posters Article No. 1 

[A variational U-Net for motion retargeting](https://dl.acm.org/citation.cfm?id=3283316)

### Related Posts

[CASA 2020: A Variational U-Net for Motion Retargeting](https://nc-moai.github.io/news/Variational_U-Net_CASA/)